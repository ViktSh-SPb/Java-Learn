### Что такое стратегия кэширования и для чего она используется?

Стратегия кэширования — это набор правил и методов, определяющих, как и когда данные должны сохраняться, обновляться или удаляться из кэша. Она помогает управлять балансом между скоростью доступа к данным и их актуальностью, а также оптимизировать использование ресурсов системы.

Цели использования:

- Повышение производительности за счет быстрого доступа к часто используемым данным.
- Снижение нагрузки на источники данных (базы данных, внешние API).
- Обеспечение высокой доступности и масштабируемости системы.

### Что такое LRU (Least Recently Used) алгоритм кэширования?

LRU (Least Recently Used) — это алгоритм управления кэшем, при котором удаляются самые давно неиспользуемые элементы при необходимости освободить место для новых данных.

Принцип работы:

- Каждое обращение к элементу обновляет его статус как "самый свежий".
- Когда кэш заполняется, удаляется элемент, который использовался дольше всего назад.
- Обычно реализуется с помощью связных списков или структур данных типа `LinkedHashMap` в Java.

Преимущества:

- Хорошо работает в сценариях с локальной временной локализацией данных.

### В чем заключается разница между стратегиями Write-Through и Write-Back?

|Стратегия|Описание|Плюсы|Минусы|
|---|---|---|---|
|Write-Through|Запись данных одновременно в кэш и в основной источник (например, базу данных).|Гарантированная актуальность данных; отказоустойчивость.|Медленная запись; нагрузка на источник данных.|
|Write-Back|Запись происходит только в кэш; обновление основного источника выполняется позже (например, при вытеснении или по таймеру).|Быстрая запись; уменьшение количества операций с источником.|Возможна потеря данных при сбое системы; сложнее обеспечить согласованность.|

### Как можно реализовать стратегию кэширования на уровне приложения?

- Использование встроенных структур данных (`HashMap`, `LinkedHashMap`) для локального кэша.
- Внедрение сторонних решений — Redis, Memcached — через клиентские библиотеки.
- Реализация уровней кэша: локальный (в памяти) + распределённый (сеть).
- Настройка TTL (Time To Live) для автоматической инвалидации.
- Обработка событийных триггеров для обновления или сброса кэша.

Пример: В Java можно использовать `LinkedHashMap` с переопределением метода `removeEldestEntry()` для реализации LRU.

### Какие стратегии и подходы используются для оптимизации производительности при работе с кэшем?

- Использование подхода "hot data" — хранение наиболее часто запрашиваемых данных.
- Настройка TTL и инвалидации, чтобы избегать устаревших данных.
- Комбинирование локального и распределённого кэша.
- Использование алгоритмов замещения, таких как LRU, LFU (Least Frequently Used), FIFO.
- Мониторинг метрик hit/miss ratio, чтобы корректировать стратегии.
- Асинхронное обновление или предзагрузка данных.

### Какие сценарии использования наиболее подходят для стратегии кэширования TTL?

Стратегия TTL хорошо подходит в случаях:

- Когда данные быстро устаревают или меняются часто (например, новости, цены).
- Для временных сессий или токенов аутентификации.
- В системах с высокой динамикой обновлений, где важно обеспечить баланс между актуальностью и производительностью.

Пример: Кэширование результатов API-запросов с TTL 5 минут.

### Как реализовать кастомную стратегию кэширования в Java?

Можно создать собственный класс-контейнер с логикой инвалидации и замещения. Например:

```java
public class CustomCache<K, V> {
    private final Map<K, CacheEntry<V>> cache = new HashMap<>();
    private final long ttlMillis;

    public CustomCache(long ttlMillis) {
        this.ttlMillis = ttlMillis;
    }

    public void put(K key, V value) {
        cache.put(key, new CacheEntry<>(value, System.currentTimeMillis()));
    }

    public V get(K key) {
        CacheEntry<V> entry = cache.get(key);
        if (entry == null || isExpired(entry)) {
            cache.remove(key);
            return null;
        }
        return entry.value;
    }

    private boolean isExpired(CacheEntry<V> entry) {
        return System.currentTimeMillis() - entry.timestamp > ttlMillis;
    }

    private static class CacheEntry<V> {
        V value;
        long timestamp;

        CacheEntry(V value, long timestamp) {
            this.value = value;
            this.timestamp = timestamp;
        }
    }
}
```

Это базовая реализация TTL-кеша.

### Какие вызовы и решения могут быть использованы для оптимизации работы кэша в распределённых системах?

- Использование распределённых систем типа Redis или Memcached.
- Репликация данных между узлами для отказоустойчивости.
- Балансировка нагрузки через кластеризацию.
- Использование Consistent Hashing для равномерного распределения ключей.
- Реализация механизма согласованности (например, через Redis Cluster).

Решения:

- Настройка репликации и автоматического восстановления.
- Использование протоколов согласования типа Raft или Paxos при необходимости согласованности.

### Какие существуют подходы к инвалидации кэша в системах с высокой доступностью?

1. TTL-инвалидация: автоматический сброс по времени жизни элементов.
2. Event-based invalidation: обновление или удаление элементов при событиях изменения данных (например, через сообщения или вебхуки).
3. Manual invalidation: явное удаление/обновление из приложения по запросу.
4. Versioning: хранение версий данных; при изменении увеличивается версия — старые данные считаются устаревшими.
5. Lazy invalidation: проверка актуальности при каждом запросе — если данные устарели, они перезагружаются.
## 1️⃣ **Выбор оборудования и конфигурации брокеров**
- **CPU**: Kafka интенсивно использует **дисковый I/O и сеть**, но также важен процессор для сериализации/десериализации сообщений.

- **RAM**: Для кэширования сообщений в page cache. Рекомендуется ≥ 64 GB для больших кластеров.
- **Диски**: SSD предпочтительнее для высокой пропускной способности. RAID не обязателен — Kafka реплицирует данные сама.
- **Сеть**: Минимум 10 Gbps для крупных потоков данных.
**Конфигурации брокеров:**
- `num.network.threads` и `num.io.threads` — количество потоков для обработки сети и дисков;
- `log.dirs` — пути хранения логов, можно указать несколько для балансировки I/O;
- `num.partitions` — количество партиций по умолчанию для топиков.
## 2️⃣ **Проектирование топиков и партиций**
- **Партиции (partitions)** — единица параллелизма:
    - Чем больше partition’ов → тем больше потребителей могут работать параллельно.
    - Хорошая практика: 1 partition на ~5-10k сообщений в секунду для одного потребителя.
- **Replication factor** — число реплик для отказоустойчивости:
    - Обычно 3, чтобы обеспечить устойчивость к сбою одного брокера.
## 3️⃣ **Настройка репликации и ISR**
- **Leader/Follower**:
    - Убедитесь, что каждая партиция имеет **реплики на разных брокерах**, чтобы избежать единой точки отказа.
- **min.insync.replicas**:
    - Определяет минимальное количество реплик в ISR для подтверждения записи.
    - Рекомендуется `min.insync.replicas = 2` при replication factor = 3.
- **acks=all** у продюсеров обеспечивает надежную запись.
## 4️⃣ **Настройка продюсеров и потребителей**
### Продюсеры:
- Использовать **batching** (`batch.size`) и **сжатие сообщений** (`compression.type = snappy/lz4`) для повышения пропускной способности.
- Настройка **linger.ms** — небольшой таймаут для пакетной отправки сообщений.
### Потребители:
- Разделение на **consumer groups** для параллельной обработки partition’ов.
- Настройка **fetch.min.bytes / fetch.max.wait.ms** для оптимальной производительности.

## 5️⃣ **Горизонтальное масштабирование кластера**
- **Добавление брокеров**:
    - Новый брокер увеличивает общую пропускную способность.
    - Можно **перераспределить партиции** с помощью `kafka-reassign-partitions.sh`.
- **Добавление партиций** в существующие топики:
    - Позволяет увеличить параллельность чтения, но порядок сообщений между старым и новым partition’ом не гарантируется.
## 6️⃣ **Мониторинг и управление нагрузкой**
- Используйте **JMX метрики** для мониторинга:
    - Throughput (записей/событий в секунду)
    - Lag потребителей
    - Репликация ISR
- Настройка **Quota** для ограничения продюсеров и потребителей при пиковых нагрузках.
## 7️⃣ **Хранение и политика retention**
- Устанавливайте `retention.ms` или `retention.bytes` с учётом объема данных.
- Для больших потоков данных можно включить **log compaction**, если важны только последние значения ключей.
## 8️⃣ **Пример топологии для высоких нагрузок**
```
Cluster: 6 Brokers
Replication Factor: 3
Topics:
  - orders: 12 partitions
  - payments: 8 partitions
  - events: 24 partitions

Producers: 10 instances, batching + compression
Consumers: 3 consumer groups per topic, parallel processing of partitions
```
- Каждая партиция распределена между брокерами для баланса нагрузки.
- Реплики обеспечивают отказоустойчивость.
- Параллельная обработка partition’ов масштабирует throughput без потери данных.
## ⚡ Резюме
Для масштабирования Kafka под большие данные нужно:
1. Правильно подобрать **железо** (SSD, RAM, сеть).
2. Проектировать **топики и партиции** с учётом параллелизма.
3. Настроить **репликацию и ISR** для отказоустойчивости.
4. Использовать **batching и сжатие** у продюсеров.
5. Масштабировать горизонтально: добавление **брокеров и партиций**.
6. Мониторить метрики и управлять lag’ом потребителей.
7. Настроить **политику хранения (retention)** и log compaction.